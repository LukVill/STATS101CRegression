library(data.table)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(ggplot2)
# Over to you! Fill in the path to your working directory. If you are on a Windows machine, you will need to use forward slashes (/) instead of backshashes (\)
# SET FILEPATH AS QUANTIUM-PROGRAM
filePath <- paste0(getwd(),"/")
data <- fread(paste0(filePath,"QVI_data.csv"))
#### Set themes for plots
theme_set(theme_bw())
theme_update(plot.title = element_text(hjust = 0.5))
#### Calculate these measures over time for each store
#### Over to you! Add a new month ID column in the data with the format yyyymm.
data[, YEARMONTH := as.numeric(format(data$DATE, "%Y%m"))]
#### Next, we define the measure calculations to use during the analysis.
# Over to you! For each store and month calculate total sales, number of customers, transactions per customer, chips per customer and the average price per unit.
## Hint: you can use uniqueN() to count distinct values in a column
unique_store <- unique(data$STORE_NBR)[order(unique(data$STORE_NBR))]
unique_month <- unique(data$YEARMONTH)[order(unique(data$YEARMONTH))]
measureOverTime <- data %>% group_by(STORE_NBR,YEARMONTH) %>% arrange(STORE_NBR,YEARMONTH) %>% summarize(totSales = sum(TOT_SALES), nCustomers = uniqueN(LYLTY_CARD_NBR), nTxnPerCust = n()/uniqueN(LYLTY_CARD_NBR), nChipsPerTxn = sum(PROD_QTY)/n(), avgPricePerUnit = sum(TOT_SALES)/sum(PROD_QTY))
#### Filter to the pre-trial period and stores with full observation periods
storesWithFullObs <- measureOverTime %>% group_by(STORE_NBR) %>% count() %>% filter(n == 12) %>% pull(STORE_NBR)
preTrialMeasures <- measureOverTime %>% filter(YEARMONTH < 201902 & STORE_NBR %in% storesWithFullObs)
#### Over to you! Create a function to calculate correlation for a measure, looping through each control store.
#### Let's define inputTable as a metric table with potential comparison stores, metricCol as the store metric used to calculate correlation on, and storeComparison as the store number of the trial store.
# pretrialmeasures is inputTable
calculateCorrelation <- function(inputTable, metricCol, storeComparison) {
calcCorrTable <- data.table(Store1 = numeric(), Store2 = numeric(), corr_measure = numeric())
storeNumbers <- unique(inputTable$STORE_NBR)
# compare to each store in pretrialmeasures
for (i in storeNumbers) {
calculatedMeasure <- data.table("Store1" = storeComparison,
"Store2" = i,
"corr_measure" = cor(inputTable %>% filter(STORE_NBR == storeComparison) %>% pull(metricCol), inputTable %>% filter(STORE_NBR == i) %>% pull(metricCol)))
calcCorrTable <- rbind(calcCorrTable, calculatedMeasure)
}
return(calcCorrTable)
}
#### Create a function to calculate a standardised magnitude distance for a measure,
#### looping through each control store
calculateMagnitudeDistance <- function(inputTable, metricCol, storeComparison) {
calcDistTable = data.table("Store1" = numeric(), "Store2" = numeric(), "YEARMONTH" =
numeric(), "measure" = numeric())
storeNumbers <- unique(inputTable$STORE_NBR)
for (i in storeNumbers) {
calculatedMeasure = data.table("Store1" = storeComparison
, "Store2" = i
, "YEARMONTH" = inputTable %>% filter(STORE_NBR == storeComparison) %>% pull(YEARMONTH)
, "measure" = abs(inputTable %>% filter(STORE_NBR == storeComparison) %>% pull(metricCol)
- inputTable %>% filter(STORE_NBR == i) %>% pull(metricCol))
)
calcDistTable <- rbind(as.data.frame(calcDistTable), as.data.frame(calculatedMeasure))
}
#### Standardise the magnitude distance so that the measure ranges from 0 to 1
distTable <- calcDistTable %>% mutate(minDist = min(measure), maxDist = max(measure))
distTable <- distTable %>% mutate(magnitudeMeasure = 1 - (measure - minDist)/(maxDist - minDist))
finalDistTable <- distTable %>% mutate(mag_measure = mean(magnitudeMeasure)) %>% arrange(Store2)
return(finalDistTable)
}
#### Over to you! Use the function you created to calculate correlations against store 77 using total sales and number of customers.
#### Hint: Refer back to the input names of the functions we created.
trial_store <- 77
corr_nSales <- calculateCorrelation(preTrialMeasures, quote(totSales), trial_store)
corr_nCustomers <- calculateCorrelation(preTrialMeasures, quote(nCustomers), trial_store)
#### Then, use the functions for calculating magnitude.
magnitude_nSales <- calculateMagnitudeDistance(preTrialMeasures, quote(totSales),
trial_store)
magnitude_nCustomers <- calculateMagnitudeDistance(preTrialMeasures,
quote(nCustomers), trial_store)
#### Over to you! Create a combined score composed of correlation and magnitude, by first merging the correlations table with the magnitude table.
#### Hint: A simple average on the scores would be 0.5 * corr_measure + 0.5 * mag_measure
corr_weight <- 0.5
score_nSales <- merge(corr_nSales, magnitude_nSales, by = c("Store1","Store2")) %>% mutate(scoreNSales = 0.5 * corr_measure + 0.5 * magnitudeMeasure)
score_nCustomers <- merge(corr_nCustomers, magnitude_nCustomers, by = c("Store1","Store2"))%>% mutate(scoreNCust = 0.5 * corr_measure + 0.5 * magnitudeMeasure)
#### Over to you! Combine scores across the drivers by first merging our sales scores and customer scores into a single table
score_nSales_v1 <- score_nSales %>% select(c("Store1","Store2","scoreNSales"))
score_nCustomers_v1 <- score_nCustomers %>% select(c("Store1","Store2","scoreNCust"))
score_Control <-  cbind(score_nSales_v1, "scoreNCust" = score_nCustomers_v1$scoreNCust)
score_Control <- score_Control %>% mutate(finalControlScore = scoreNSales * 0.5 + scoreNCust * 0.5)
#### Select control stores based on the highest matching store (closest to 1 but
#### not the store itself, i.e. the second ranked highest store)
#### Over to you! Select the most appropriate control store for trial store 77 by finding the store with the highest final score.
control_store <- score_Control %>% filter(Store2 != trial_store) %>% arrange(desc(finalControlScore)) %>% slice(1) %>% pull(Store2)
control_store
#### Visual checks on trends based on the drivers
measureOverTimeSales <- measureOverTime
pastSales <- measureOverTimeSales %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", ifelse(STORE_NBR == control_store, "Control", "Other stores")), TransactionMonth = as.Date(paste(YEARMONTH %/% 100, YEARMONTH %% 100, 1, sep = "-"),"%Y-%m-%d")) %>% arrange("YEARMONTH","Store_type") %>% filter(YEARMONTH < 201903)
ggplot(pastSales) + geom_line(aes(TransactionMonth, totSales, color = Store_type)) + labs(x = "Month of operation", y = "Total sales", title = "Total sales by month")
#### Over to you! Conduct visual checks on customer count trends by comparing the trial store to the control store and other stores.
#### Hint: Look at the previous plot.
measureOverTimeCusts <- measureOverTime
pastCustomers <- measureOverTimeCusts %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", ifelse(STORE_NBR == control_store, "Control", "Other stores")), TransactionMonth = as.Date(paste(YEARMONTH %/% 100, YEARMONTH %% 100, 1, sep = "-"),"%Y-%m-%d")) %>% arrange("YEARMONTH","Store_type") %>% filter(YEARMONTH < 201903)
ggplot(pastCustomers) + geom_line(aes(TransactionMonth, nCustomers, color = Store_type)) + labs(x = "Month of operation", y = "Total Customers", title = "Total Customers by month - Trial Store 77") + ylim(NA,75)
#### Scale pre-trial control sales to match pre-trial trial store sales
scalingFactorForControlSales <- sum(preTrialMeasures %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(totSales)) / sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902) %>% pull(totSales))
#### Apply the scaling factor
measureOverTimeSales <- measureOverTime
scaledControlSales <- measureOverTimeSales %>% filter(STORE_NBR == control_store) %>% mutate(controlSales = totSales * scalingFactorForControlSales)
#### Over to you! Calculate the percentage difference between scaled control sales and trial sales
percentDiff <- ((scaledControlSales %>% pull(controlSales))-(measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))) / (measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))
percentageDiff <- scaledControlSales
percentageDiff["percentageDiff"] <- percentDiff
#### As our null hypothesis is that the trial period is the same as the pre-trial period, let's take the standard deviation based on the scaled percentage difference in the pre-trial period
stdDev <- sd(percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(percentageDiff))
#### Note that there are 8 months in the pre-trial period
#### hence 8 - 1 = 7 degrees of freedom
degreesOfFreedom <- 7
#### We will test with a null hypothesis of there being 0 difference between trial and control stores.
#### Over to you! Calculate the t-values for the trial months. After that, find the 95th percentile of the t distribution with the appropriate degrees of freedom
#### to check whether the hypothesis is statistically significant.
#### Hint: The test statistic here is (x - u)/standard deviation
# t test between scaled control sales and trial sales during trial period using pretrial stddev
control_mean <- mean(percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(controlSales))
trial_mean <- mean(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH >= 201902) %>% pull(totSales))
tval <- (control_mean - trial_mean) / stdDev
tval
pt(tval,df = degreesOfFreedom)
measureOverTimeSales <- measureOverTime
#### Trial and control store total sales
#### Over to you! Create new variables Store_type, totSales and TransactionMonth in the data table.
pastSales <- measureOverTimeSales %>% select(STORE_NBR, YEARMONTH, totSales) %>% filter(YEARMONTH >= 201902) %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", "Control"))
#### Control store 95th percentile
pastSales_Controls95 <- pastSales %>% filter(Store_type == "Control") %>% mutate(totSales = totSales * (1 + stdDev * 2), Store_type = "Control 95th % confidence interval")
#### Control store 5th percentile
pastSales_Controls5 <- pastSales %>% filter(Store_type == "Control") %>% mutate(totSales = totSales * (1 - stdDev * 2), Store_type = "Control 5th % confidence interval")
trialAssessment <- rbind(pastSales,pastSales_Controls95)
trialAssessment <- rbind(trialAssessment, pastSales_Controls5)
trialAssessment <- trialAssessment %>% mutate(TransactionMonth = as.numeric(substr(as.character(YEARMONTH), 5, 7)))
#### Plotting these in one nice graph
ggplot(trialAssessment, aes(TransactionMonth, totSales, color = Store_type)) + geom_rect(data = trialAssessment %>% filter(YEARMONTH < 201905 & YEARMONTH > 201901), aes(xmin = min(TransactionMonth), xmax = max(TransactionMonth), ymin = 0, ymax = Inf, color = NULL), show.legend = FALSE) + geom_line() + labs(x = "Month of operation", y = "Total sales", title = "Total sales by month")
#### This would be a repeat of the steps before for total sales
#### Scale pre-trial control customers to match pre-trial trial store customers
#### Over to you! Compute a scaling factor to align control store customer counts to our trial store.
#### Then, apply the scaling factor to control store customer counts.
#### Finally, calculate the percentage difference between scaled control store customers and trial customers.
scalingFactorForControlCust <- sum(preTrialMeasures %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(nCustomers)) / sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902) %>% pull(nCustomers))
measureOverTimeCusts <- measureOverTime
scaledControlCustomers <- measureOverTimeCusts %>% filter(STORE_NBR == control_store) %>% mutate(controlCust = nCustomers * scalingFactorForControlCust)
percentDiff <- ((scaledControlCustomers %>% pull(nCustomers))-(measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(nCustomers))) / (measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(nCustomers))
percentageDiff <- scaledControlSales
percentageDiff["percentageDiff"] <- percentDiff
#### As our null hypothesis is that the trial period is the same as the pre-trial period, let's take the standard deviation based on the scaled percentage difference in the pre-trial period
stdDev <- sd(percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(percentageDiff))
degreesOfFreedom <- 7
pastCustomers <- measureOverTimeSales %>% select(STORE_NBR, YEARMONTH, nCustomers) %>% filter(YEARMONTH >= 201902) %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", "Control"))
#### Trial and control store number of customers
pastCustomers_Controls95 <- pastCustomers %>% filter(Store_type == "Control") %>% mutate(nCustomers = nCustomers * (1 + stdDev * 2), Store_type = "Control 95th % confidence")
pastCustomers_Controls5 <- pastCustomers %>% filter(Store_type == "Control") %>% mutate(nCustomers = nCustomers * (1 - stdDev * 2), Store_type = "Control 5th % confidence")
trialAssessment <- rbind(pastCustomers,pastCustomers_Controls95)
trialAssessment <- rbind(trialAssessment, pastCustomers_Controls5)
trialAssessment <- trialAssessment %>% mutate(TransactionMonth = as.numeric(substr(as.character(YEARMONTH), 5, 7)))
# filter out to control store
trialAssessment <- trialAssessment %>% filter(STORE_NBR == control_store | STORE_NBR == trial_store)
ggplot(trialAssessment, aes(TransactionMonth, nCustomers, color = Store_type)) + geom_rect(data = trialAssessment %>% filter(YEARMONTH < 201905 & YEARMONTH > 201901), aes(xmin = min(TransactionMonth), xmax = max(TransactionMonth), ymin = 0, ymax = Inf, color = NULL), show.legend = FALSE) + geom_line() + labs(x = "Month of operation", y = "Total customers", title = "Total sales by month - Trial Store 77")
#### Over to you! Use the functions we created earlier to calculate correlations and magnitude for each potential control store
trial_store <- 86
corr_nSales <- calculateCorrelation(preTrialMeasures, quote(totSales), trial_store)
corr_nCustomers <- calculateCorrelation(preTrialMeasures, quote(nCustomers), trial_store)
#### Then, use the functions for calculating magnitude.
magnitude_nSales <- calculateMagnitudeDistance(preTrialMeasures, quote(totSales),
trial_store)
magnitude_nCustomers <- calculateMagnitudeDistance(preTrialMeasures,
quote(nCustomers), trial_store)
#### Now, create a combined score composed of correlation and magnitude
corr_weight <- 0.5
score_nSales <- merge(corr_nSales, magnitude_nSales, by = c("Store1","Store2")) %>% mutate(scoreNSales = 0.5 * corr_measure + 0.5 * magnitudeMeasure)
score_nCustomers <- merge(corr_nCustomers, magnitude_nCustomers, by = c("Store1","Store2"))%>% mutate(scoreNCust = 0.5 * corr_measure + 0.5 * magnitudeMeasure)
score_nSales_v1 <- score_nSales %>% select(c("Store1","Store2","scoreNSales"))
score_nCustomers_v1 <- score_nCustomers %>% select(c("Store1","Store2","scoreNCust"))
score_Control <-  cbind(score_nSales_v1, "scoreNCust" = score_nCustomers_v1$scoreNCust)
score_Control <- score_Control %>% mutate(finalControlScore = scoreNSales * 0.5 + scoreNCust * 0.5)
control_store <- score_Control %>% filter(Store2 != trial_store) %>% arrange(desc(finalControlScore)) %>% slice(1) %>% pull(Store2)
control_store
#### Visual checks on trends based on the drivers
measureOverTimeSales <- measureOverTime
pastSales <- measureOverTimeSales %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", ifelse(STORE_NBR == control_store, "Control", "Other stores")), TransactionMonth = as.Date(paste(YEARMONTH %/% 100, YEARMONTH %% 100, 1, sep = "-"),"%Y-%m-%d")) %>% arrange("YEARMONTH","Store_type") %>% filter(YEARMONTH < 201903)
ggplot(pastSales) + geom_line(aes(TransactionMonth, totSales, color = Store_type)) + labs(x = "Month of operation", y = "Total sales", title = "Total sales by month")
#### Over to you! Conduct visual checks on customer count trends by comparing the trial store to the control store and other stores.
#### Hint: Look at the previous plot.
measureOverTimeCusts <- measureOverTime
pastCustomers <- measureOverTimeCusts %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", ifelse(STORE_NBR == control_store, "Control", "Other stores")), TransactionMonth = as.Date(paste(YEARMONTH %/% 100, YEARMONTH %% 100, 1, sep = "-"),"%Y-%m-%d")) %>% arrange("YEARMONTH","Store_type") %>% filter(YEARMONTH < 201903)
ggplot(pastCustomers) + geom_line(aes(TransactionMonth, nCustomers, color = Store_type)) + labs(x = "Month of operation", y = "Total Customers", title = "Total Customers by month - Trial 86")
#### Scale pre-trial control sales to match pre-trial trial store sales
scalingFactorForControlSales <- sum(preTrialMeasures %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(totSales)) / sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902) %>% pull(totSales))
#### Apply the scaling factor
measureOverTimeSales <- measureOverTime
scaledControlSales <- measureOverTimeSales %>% filter(STORE_NBR == control_store) %>% mutate(controlSales = totSales * scalingFactorForControlSales)
#### Over to you! Calculate the percentage difference between scaled control sales and trial sales
percentDiff <- ((scaledControlSales %>% pull(controlSales))-(measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))) / (measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))
percentageDiff <- scaledControlSales
percentageDiff["percentageDiff"] <- percentDiff
#### As our null hypothesis is that the trial period is the same as the pre-trial period, let's take the standard deviation based on the scaled percentage difference in the pre-trial period
stdDev <- sd(percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(percentageDiff))
#### Note that there are 8 months in the pre-trial period
#### hence 8 - 1 = 7 degrees of freedom
degreesOfFreedom <- 7
#### We will test with a null hypothesis of there being 0 difference between trial and control stores.
#### Over to you! Calculate the t-values for the trial months. After that, find the 95th percentile of the t distribution with the appropriate degrees of freedom
#### to check whether the hypothesis is statistically significant.
#### Hint: The test statistic here is (x - u)/standard deviation
# t test between scaled control sales and trial sales during trial period using pretrial stddev
control_mean <- mean(percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(controlSales))
trial_mean <- mean(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH >= 201902) %>% pull(totSales))
tval <- (control_mean - trial_mean) / stdDev
tval
pt(tval,df = degreesOfFreedom)
measureOverTimeSales <- measureOverTime
#### Trial and control store total sales
#### Over to you! Create new variables Store_type, totSales and TransactionMonth in the data table.
pastSales <- measureOverTimeSales %>% select(STORE_NBR, YEARMONTH, totSales) %>% filter(YEARMONTH >= 201902) %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", "Control"))
#### Control store 95th percentile
pastSales_Controls95 <- pastSales %>% filter(Store_type == "Control") %>% mutate(totSales = totSales * (1 + stdDev * 2), Store_type = "Control 95th % confidence interval")
#### Control store 5th percentile
pastSales_Controls5 <- pastSales %>% filter(Store_type == "Control") %>% mutate(totSales = totSales * (1 - stdDev * 2), Store_type = "Control 5th % confidence interval")
trialAssessment <- rbind(pastSales,pastSales_Controls95)
trialAssessment <- rbind(trialAssessment, pastSales_Controls5)
trialAssessment <- trialAssessment %>% mutate(TransactionMonth = as.numeric(substr(as.character(YEARMONTH), 5, 7)))
# filter out to control store
trialAssessment <- trialAssessment %>% filter(STORE_NBR == control_store | STORE_NBR == trial_store)
#### Plotting these in one nice graph
ggplot(trialAssessment, aes(TransactionMonth, totSales, color = Store_type)) + geom_rect(data = trialAssessment %>% filter(YEARMONTH < 201905 & YEARMONTH > 201901), aes(xmin = min(TransactionMonth), xmax = max(TransactionMonth), ymin = 0, ymax = Inf, color = NULL), show.legend = FALSE) + geom_line() + labs(x = "Month of operation", y = "Total sales", title = "Total sales by month - Trial Store 86")
#### This would be a repeat of the steps before for total sales
#### Scale pre-trial control customers to match pre-trial trial store customers
#### Over to you! Compute a scaling factor to align control store customer counts to our trial store.
#### Then, apply the scaling factor to control store customer counts.
#### Finally, calculate the percentage difference between scaled control store customers and trial customers.
scalingFactorForControlCust <- sum(preTrialMeasures %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(nCustomers)) / sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902) %>% pull(nCustomers))
measureOverTimeCusts <- measureOverTime
scaledControlCustomers <- measureOverTimeCusts %>% filter(STORE_NBR == control_store) %>% mutate(controlCust = nCustomers * scalingFactorForControlCust)
percentDiff <- ((scaledControlCustomers %>% pull(nCustomers))-(measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(nCustomers))) / (measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(nCustomers))
percentageDiff <- scaledControlSales
percentageDiff["percentageDiff"] <- percentDiff
#### As our null hypothesis is that the trial period is the same as the pre-trial period, let's take the standard deviation based on the scaled percentage difference in the pre-trial period
stdDev <- sd(percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(percentageDiff))
degreesOfFreedom <- 7
pastCustomers <- measureOverTimeSales %>% select(STORE_NBR, YEARMONTH, nCustomers) %>% filter(YEARMONTH >= 201902) %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", "Control"))
#### Trial and control store number of customers
pastCustomers_Controls95 <- pastCustomers %>% filter(Store_type == "Control") %>% mutate(nCustomers = nCustomers * (1 + stdDev * 2), Store_type = "Control 95th % confidence")
pastCustomers_Controls5 <- pastCustomers %>% filter(Store_type == "Control") %>% mutate(nCustomers = nCustomers * (1 - stdDev * 2), Store_type = "Control 95th % confidence")
trialAssessment <- rbind(pastCustomers,pastCustomers_Controls95)
trialAssessment <- rbind(trialAssessment, pastCustomers_Controls5)
trialAssessment <- trialAssessment %>% mutate(TransactionMonth = as.numeric(substr(as.character(YEARMONTH), 5, 7)))
ggplot(trialAssessment, aes(TransactionMonth, nCustomers, color = Store_type)) + geom_rect(data = trialAssessment %>% filter(YEARMONTH < 201905 & YEARMONTH > 201901), aes(xmin = min(TransactionMonth), xmax = max(TransactionMonth), ymin = 0, ymax = Inf, color = NULL), show.legend = FALSE) + geom_line() + labs(x = "Month of operation", y = "Total customers", title = "Total sales by month")
#### Over to you! Use the functions we created earlier to calculate correlations and magnitude for each potential control store
trial_store <- 88
corr_nSales <- calculateCorrelation(preTrialMeasures, quote(totSales), trial_store)
corr_nCustomers <- calculateCorrelation(preTrialMeasures, quote(nCustomers), trial_store)
#### Then, use the functions for calculating magnitude.
magnitude_nSales <- calculateMagnitudeDistance(preTrialMeasures, quote(totSales),
trial_store)
magnitude_nCustomers <- calculateMagnitudeDistance(preTrialMeasures,
quote(nCustomers), trial_store)
#### Now, create a combined score composed of correlation and magnitude
corr_weight <- 0.5
score_nSales <- merge(corr_nSales, magnitude_nSales, by = c("Store1","Store2")) %>% mutate(scoreNSales = 0.5 * corr_measure + 0.5 * magnitudeMeasure)
score_nCustomers <- merge(corr_nCustomers, magnitude_nCustomers, by = c("Store1","Store2"))%>% mutate(scoreNCust = 0.5 * corr_measure + 0.5 * magnitudeMeasure)
score_nSales_v1 <- score_nSales %>% select(c("Store1","Store2","scoreNSales"))
score_nCustomers_v1 <- score_nCustomers %>% select(c("Store1","Store2","scoreNCust"))
score_Control <-  cbind(score_nSales_v1, "scoreNCust" = score_nCustomers_v1$scoreNCust)
score_Control <- score_Control %>% mutate(finalControlScore = scoreNSales * 0.5 + scoreNCust * 0.5)
control_store <- score_Control %>% filter(Store2 != trial_store) %>% arrange(desc(finalControlScore)) %>% slice(1) %>% pull(Store2)
control_store
#### Visual checks on trends based on the drivers
measureOverTimeSales <- measureOverTime
pastSales <- measureOverTimeSales %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", ifelse(STORE_NBR == control_store, "Control", "Other stores")), TransactionMonth = as.Date(paste(YEARMONTH %/% 100, YEARMONTH %% 100, 1, sep = "-"),"%Y-%m-%d")) %>% arrange("YEARMONTH","Store_type") %>% filter(YEARMONTH < 201903)
ggplot(pastSales) + geom_line(aes(TransactionMonth, totSales, color = Store_type)) + labs(x = "Month of operation", y = "Total sales", title = "Total sales by month")
#### Over to you! Conduct visual checks on customer count trends by comparing the trial store to the control store and other stores.
#### Hint: Look at the previous plot.
measureOverTimeCusts <- measureOverTime
pastCustomers <- measureOverTimeCusts %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", ifelse(STORE_NBR == control_store, "Control", "Other stores")), TransactionMonth = as.Date(paste(YEARMONTH %/% 100, YEARMONTH %% 100, 1, sep = "-"),"%Y-%m-%d")) %>% arrange("YEARMONTH","Store_type") %>% filter(YEARMONTH < 201903)
ggplot(pastCustomers) + geom_line(aes(TransactionMonth, nCustomers, color = Store_type)) + labs(x = "Month of operation", y = "Total Customers", title = "Total Customers by month - Trial Store 88")
#### Scale pre-trial control sales to match pre-trial trial store sales
scalingFactorForControlSales <- sum(preTrialMeasures %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(totSales)) / sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902) %>% pull(totSales))
#### Apply the scaling factor
measureOverTimeSales <- measureOverTime
scaledControlSales <- measureOverTimeSales %>% filter(STORE_NBR == control_store) %>% mutate(controlSales = totSales * scalingFactorForControlSales)
#### Over to you! Calculate the percentage difference between scaled control sales and trial sales
percentDiff <- ((scaledControlSales %>% pull(controlSales))-(measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))) / (measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))
percentageDiff <- scaledControlSales
percentageDiff["percentageDiff"] <- percentDiff
#### As our null hypothesis is that the trial period is the same as the pre-trial period, let's take the standard deviation based on the scaled percentage difference in the pre-trial period
stdDev <- sd(percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(percentageDiff))
#### Note that there are 8 months in the pre-trial period
#### hence 8 - 1 = 7 degrees of freedom
degreesOfFreedom <- 7
#### We will test with a null hypothesis of there being 0 difference between trial and control stores.
#### Over to you! Calculate the t-values for the trial months. After that, find the 95th percentile of the t distribution with the appropriate degrees of freedom
#### to check whether the hypothesis is statistically significant.
#### Hint: The test statistic here is (x - u)/standard deviation
# t test between scaled control sales and trial sales during trial period using pretrial stddev
control_mean <- mean(percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(controlSales))
trial_mean <- mean(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH >= 201902) %>% pull(totSales))
tval <- (control_mean - trial_mean) / stdDev
tval
pt(tval,df = degreesOfFreedom)
measureOverTimeSales <- measureOverTime
#### Trial and control store total sales
#### Over to you! Create new variables Store_type, totSales and TransactionMonth in the data table.
pastSales <- measureOverTimeSales %>% select(STORE_NBR, YEARMONTH, totSales) %>% filter(YEARMONTH >= 201902) %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", "Control"))
#### Control store 95th percentile
pastSales_Controls95 <- pastSales %>% filter(Store_type == "Control") %>% mutate(totSales = totSales * (1 + stdDev * 2), Store_type = "Control 95th % confidence interval")
#### Control store 5th percentile
pastSales_Controls5 <- pastSales %>% filter(Store_type == "Control") %>% mutate(totSales = totSales * (1 - stdDev * 2), Store_type = "Control 5th % confidence interval")
trialAssessment <- rbind(pastSales,pastSales_Controls95)
trialAssessment <- rbind(trialAssessment, pastSales_Controls5)
trialAssessment <- trialAssessment %>% mutate(TransactionMonth = as.numeric(substr(as.character(YEARMONTH), 5, 7)))
# filter out to control store
trialAssessment <- trialAssessment %>% filter(STORE_NBR == control_store | STORE_NBR == trial_store)
#### Plotting these in one nice graph
ggplot(trialAssessment, aes(TransactionMonth, totSales, color = Store_type)) + geom_rect(data = trialAssessment %>% filter(YEARMONTH < 201905 & YEARMONTH > 201901), aes(xmin = min(TransactionMonth), xmax = max(TransactionMonth), ymin = 0, ymax = Inf, color = NULL), show.legend = FALSE) + geom_line() + labs(x = "Month of operation", y = "Total sales", title = "Total sales by month - Trial Store 88")
#### Scale pre-trial control sales to match pre-trial trial store sales
scalingFactorForControlSales <- sum(preTrialMeasures %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(totSales)) / sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902) %>% pull(totSales))
#### Apply the scaling factor
measureOverTimeSales <- measureOverTime
scaledControlSales <- measureOverTimeSales %>% filter(STORE_NBR == control_store) %>% mutate(controlSales = totSales * scalingFactorForControlSales)
#### Over to you! Calculate the percentage difference between scaled control sales and trial sales
percentDiff <- ((scaledControlSales %>% pull(controlSales))-(measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))) / (measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(totSales))
percentageDiff <- scaledControlSales
percentageDiff["percentageDiff"] <- percentDiff
#### As our null hypothesis is that the trial period is the same as the pre-trial period, let's take the standard deviation based on the scaled percentage difference in the pre-trial period
stdDev <- sd(percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(percentageDiff))
#### Note that there are 8 months in the pre-trial period
#### hence 8 - 1 = 7 degrees of freedom
degreesOfFreedom <- 7
#### We will test with a null hypothesis of there being 0 difference between trial and control stores.
#### Over to you! Calculate the t-values for the trial months. After that, find the 95th percentile of the t distribution with the appropriate degrees of freedom
#### to check whether the hypothesis is statistically significant.
#### Hint: The test statistic here is (x - u)/standard deviation
# t test between scaled control sales and trial sales during trial period using pretrial stddev
control_mean <- mean(percentageDiff %>% filter(YEARMONTH >= 201902) %>% pull(controlSales))
trial_mean <- mean(measureOverTime %>% filter(STORE_NBR == trial_store & YEARMONTH >= 201902) %>% pull(totSales))
tval <- (control_mean - trial_mean) / stdDev
tval
pt(tval,df = degreesOfFreedom)
measureOverTimeSales <- measureOverTime
#### Trial and control store total sales
#### Over to you! Create new variables Store_type, totSales and TransactionMonth in the data table.
pastSales <- measureOverTimeSales %>% select(STORE_NBR, YEARMONTH, totSales) %>% filter(YEARMONTH >= 201902) %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", "Control"))
#### Control store 95th percentile
pastSales_Controls95 <- pastSales %>% filter(Store_type == "Control") %>% mutate(totSales = totSales * (1 + stdDev * 2), Store_type = "Control 95th % confidence interval")
#### Control store 5th percentile
pastSales_Controls5 <- pastSales %>% filter(Store_type == "Control") %>% mutate(totSales = totSales * (1 - stdDev * 2), Store_type = "Control 5th % confidence interval")
trialAssessment <- rbind(pastSales,pastSales_Controls95)
trialAssessment <- rbind(trialAssessment, pastSales_Controls5)
trialAssessment <- trialAssessment %>% mutate(TransactionMonth = as.numeric(substr(as.character(YEARMONTH), 5, 7)))
#### Plotting these in one nice graph
ggplot(trialAssessment, aes(TransactionMonth, totSales, color = Store_type)) + geom_rect(data = trialAssessment %>% filter(YEARMONTH < 201905 & YEARMONTH > 201901), aes(xmin = min(TransactionMonth), xmax = max(TransactionMonth), ymin = 0, ymax = Inf, color = NULL), show.legend = FALSE) + geom_line() + labs(x = "Month of operation", y = "Total sales", title = "Total sales by month")
#### This would be a repeat of the steps before for total sales
#### Scale pre-trial control customers to match pre-trial trial store customers
#### Over to you! Compute a scaling factor to align control store customer counts to our trial store.
#### Then, apply the scaling factor to control store customer counts.
#### Finally, calculate the percentage difference between scaled control store customers and trial customers.
scalingFactorForControlCust <- sum(preTrialMeasures %>% filter(STORE_NBR == trial_store & YEARMONTH < 201902) %>% pull(nCustomers)) / sum(preTrialMeasures %>% filter(STORE_NBR == control_store & YEARMONTH < 201902) %>% pull(nCustomers))
measureOverTimeCusts <- measureOverTime
scaledControlCustomers <- measureOverTimeCusts %>% filter(STORE_NBR == control_store) %>% mutate(controlCust = nCustomers * scalingFactorForControlCust)
percentDiff <- ((scaledControlCustomers %>% pull(nCustomers))-(measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(nCustomers))) / (measureOverTime %>% filter(STORE_NBR == trial_store) %>% pull(nCustomers))
percentageDiff <- scaledControlSales
percentageDiff["percentageDiff"] <- percentDiff
#### As our null hypothesis is that the trial period is the same as the pre-trial period, let's take the standard deviation based on the scaled percentage difference in the pre-trial period
stdDev <- sd(percentageDiff %>% filter(YEARMONTH < 201902) %>% pull(percentageDiff))
degreesOfFreedom <- 7
pastCustomers <- measureOverTimeSales %>% select(STORE_NBR, YEARMONTH, nCustomers) %>% filter(YEARMONTH >= 201902) %>% mutate(Store_type = ifelse(STORE_NBR == trial_store, "Trial", "Control"))
#### Trial and control store number of customers
pastCustomers_Controls95 <- pastCustomers %>% filter(Store_type == "Control") %>% mutate(nCustomers = nCustomers * (1 + stdDev * 2), Store_type = "Control 95th % confidence")
pastCustomers_Controls5 <- pastCustomers %>% filter(Store_type == "Control") %>% mutate(nCustomers = nCustomers * (1 - stdDev * 2), Store_type = "Control 95th % confidence")
trialAssessment <- rbind(pastCustomers,pastCustomers_Controls95)
trialAssessment <- rbind(trialAssessment, pastCustomers_Controls5)
trialAssessment <- trialAssessment %>% mutate(TransactionMonth = as.numeric(substr(as.character(YEARMONTH), 5, 7)))
ggplot(trialAssessment, aes(TransactionMonth, nCustomers, color = Store_type)) + geom_rect(data = trialAssessment %>% filter(YEARMONTH < 201905 & YEARMONTH > 201901), aes(xmin = min(TransactionMonth), xmax = max(TransactionMonth), ymin = 0, ymax = Inf, color = NULL), show.legend = FALSE) + geom_line() + labs(x = "Month of operation", y = "Total customers", title = "Total sales by month")
# plot
ggplot(chip_premlife) + geom_bar(aes(x = Customer_Segment, y = Total_Sales, fill = Customer_Segment), stat = "identity") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "Total Sales per Customer Premium/Lifestage Type of Chips", x = "Premium/Lifestage Type", y = "Total Sales")
# plot
ggplot(chip_premlife) + geom_bar(aes(x = Customer_Segment, y = Total_Sales), stat = "identity") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "Total Sales per Customer Premium/Lifestage Type of Chips", x = "Premium/Lifestage Type", y = "Total Sales")
# plot
ggplot(segdata_v1) + geom_bar(aes(x = Customer_Segment, y = Avg_Total), stat = "identity") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "Average Total Sales per Customer Premium/Lifestage Type", x = "Premium/Lifestage Type", y = "Average Total Sales") + geom_hline(yintercept = 7.8)
# plot
ggplot(segdata_v1) + geom_bar(aes(x = Customer_Segment, y = Avg_Total), stat = "identity") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "Average Total Sales per Customer Premium/Lifestage Type", x = "Premium/Lifestage Type", y = "Average Total Sales") + geom_hline(yintercept = 7.3)
# plot
ggplot(segdata_v1) + geom_bar(aes(x = Customer_Segment, y = Avg_Total), stat = "identity") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "Average Total Sales per Customer Premium/Lifestage Type", x = "Premium/Lifestage Type", y = "Average Total Sales") + geom_hline(yintercept = 7.4)
# plot
ggplot(segdata_v1) + geom_bar(aes(x = Customer_Segment, y = Avg_Total), stat = "identity") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "Average Total Sales per Customer Premium/Lifestage Type", x = "Premium/Lifestage Type", y = "Average Total Sales") + geom_hline(yintercept = 7.5)
# plot
ggplot(segdata_v1) + geom_bar(aes(x = Customer_Segment, y = Avg_Total), stat = "identity") + theme(axis.text.x = element_text(angle = 90)) + labs(title = "Average Total Sales per Customer Premium/Lifestage Type", x = "Premium/Lifestage Type", y = "Average Total Sales") + geom_hline(yintercept = 7.5, color = "red")
top5brands
# make frequency plot of different brands for young mid age singles/couples
life_prem_brand_data <- data[(LIFESTAGE == "YOUNG SINGLES/COUPLES" | LIFESTAGE == "MIDAGE SINGLES/COUPLES") & grepl("CHIP",toupper(data$PROD_NAME)) & PREMIUM_CUSTOMER == "Mainstream",c("LYLTY_CARD_NBR","PROD_NAME","LIFESTAGE","PREMIUM_CUSTOMER","BRAND")]
freq_brand <- table(life_prem_brand_data$BRAND)
ggplot() + geom_bar(aes(x = names(freq_brand), y = freq_brand, fill = names(freq_brand)), stat="identity") + labs(title = "Frequencies of Chip Brand Purchases for \n Mainstream Young and Midage Singles/Couples", x = "Brand Name", y = "Frequency (total purchases)", fill = "Brand Names")
#### Over to you! Use the function you created to calculate correlations against store 77 using total sales and number of customers.
#### Hint: Refer back to the input names of the functions we created.
trial_store <- 77
corr_nSales <- calculateCorrelation(preTrialMeasures, quote(totSales), trial_store)
corr_nCustomers <- calculateCorrelation(preTrialMeasures, quote(nCustomers), trial_store)
#### Then, use the functions for calculating magnitude.
magnitude_nSales <- calculateMagnitudeDistance(preTrialMeasures, quote(totSales),
trial_store)
magnitude_nCustomers <- calculateMagnitudeDistance(preTrialMeasures,
quote(nCustomers), trial_store)
#### Over to you! Create a combined score composed of correlation and magnitude, by first merging the correlations table with the magnitude table.
#### Hint: A simple average on the scores would be 0.5 * corr_measure + 0.5 * mag_measure
corr_weight <- 0.5
score_nSales <- merge(corr_nSales, magnitude_nSales, by = c("Store1","Store2")) %>% mutate(scoreNSales = 0.5 * corr_measure + 0.5 * magnitudeMeasure)
score_nCustomers <- merge(corr_nCustomers, magnitude_nCustomers, by = c("Store1","Store2"))%>% mutate(scoreNCust = 0.5 * corr_measure + 0.5 * magnitudeMeasure)
#### Over to you! Combine scores across the drivers by first merging our sales scores and customer scores into a single table
score_nSales_v1 <- score_nSales %>% select(c("Store1","Store2","scoreNSales"))
score_nCustomers_v1 <- score_nCustomers %>% select(c("Store1","Store2","scoreNCust"))
score_Control <-  cbind(score_nSales_v1, "scoreNCust" = score_nCustomers_v1$scoreNCust)
score_Control <- score_Control %>% mutate(finalControlScore = scoreNSales * 0.5 + scoreNCust * 0.5)
#### Select control stores based on the highest matching store (closest to 1 but
#### not the store itself, i.e. the second ranked highest store)
#### Over to you! Select the most appropriate control store for trial store 77 by finding the store with the highest final score.
control_store <- score_Control %>% filter(Store2 != trial_store) %>% arrange(desc(finalControlScore)) %>% slice(1) %>% pull(Store2)
control_store
#### Over to you! Use the functions we created earlier to calculate correlations and magnitude for each potential control store
trial_store <- 86
corr_nSales <- calculateCorrelation(preTrialMeasures, quote(totSales), trial_store)
corr_nCustomers <- calculateCorrelation(preTrialMeasures, quote(nCustomers), trial_store)
#### Then, use the functions for calculating magnitude.
magnitude_nSales <- calculateMagnitudeDistance(preTrialMeasures, quote(totSales),
trial_store)
magnitude_nCustomers <- calculateMagnitudeDistance(preTrialMeasures,
quote(nCustomers), trial_store)
#### Now, create a combined score composed of correlation and magnitude
corr_weight <- 0.5
score_nSales <- merge(corr_nSales, magnitude_nSales, by = c("Store1","Store2")) %>% mutate(scoreNSales = 0.5 * corr_measure + 0.5 * magnitudeMeasure)
score_nCustomers <- merge(corr_nCustomers, magnitude_nCustomers, by = c("Store1","Store2"))%>% mutate(scoreNCust = 0.5 * corr_measure + 0.5 * magnitudeMeasure)
score_nSales_v1 <- score_nSales %>% select(c("Store1","Store2","scoreNSales"))
score_nCustomers_v1 <- score_nCustomers %>% select(c("Store1","Store2","scoreNCust"))
score_Control <-  cbind(score_nSales_v1, "scoreNCust" = score_nCustomers_v1$scoreNCust)
score_Control <- score_Control %>% mutate(finalControlScore = scoreNSales * 0.5 + scoreNCust * 0.5)
control_store <- score_Control %>% filter(Store2 != trial_store) %>% arrange(desc(finalControlScore)) %>% slice(1) %>% pull(Store2)
control_store
library(knitr)
library(tidyverse)
library(tidymodels)
setwd("C:/Users/Luke Villanueva/source/repos/LukVill/code/R/stats101c/STATS101CRegression")
paste0(getwd(),"/train.csv")
paste0(getwd(),"/train.csv")
gsub("hello","oi","hell")
gsub("hello","oi","nah")
gsub("hello","hell","nah")
gsub("hello","hell","nah")
help(gsub)
gsub(pattern = "hello world", replacement = "nah", x = "hell")
gsub(pattern = "hello world", replacement = "nah", x = ".")
gsub(pattern = "hello world", replacement = "hello", x = "")
gsub(pattern = "hello world", replacement = "hello", x = "fdjksladfjals")
gsub(pattern = "hello world", replacement = "hello")
gsub(pattern = "hello world", replacement = "hello", x = "world")
gsub(pattern = "hello world", x = "world")
gsub("([ab])", "\\1_\\1_", "abc and ABC")
gsub(pattern = "hello world", replacement = "hello", x = "world")
gsub("([ab])", "\\1_\\1_", "abc and ABC")
gsub(pattern = "world", replacement = "hello", x = "hello world")
gsub("\\","/","C:\Users\Luke Villanueva\source\repos\LukVill\code\R\stats101c\STATS101CRegression")
gsub("\","/","C:\Users\Luke Villanueva\source\repos\LukVill\code\R\stats101c\STATS101CRegression")
gsub("\\","\/","C:\Users\Luke Villanueva\source\repos\LukVill\code\R\stats101c\STATS101CRegression")
gsub("\\","//","C:\Users\Luke Villanueva\source\repos\LukVill\code\R\stats101c\STATS101CRegression")
gsub("\\\","/","C:\Users\Luke Villanueva\source\repos\LukVill\code\R\stats101c\STATS101CRegression")
gsub("\\\\","/","C:\Users\Luke Villanueva\source\repos\LukVill\code\R\stats101c\STATS101CRegression")
gsub("\\\\","","C:\Users\Luke Villanueva\source\repos\LukVill\code\R\stats101c\STATS101CRegression")
gsub("\\\\", "", "C:\Users\Luke Villanueva\source\repos\LukVill\code\R\stats101c\STATS101CRegression")
gsub("\\\\","","""C:\Users\Luke Villanueva\source\repos\LukVill\code\R\stats101c\STATS101CRegression""")
gsub("\\\\","",""C:\Users\Luke Villanueva\source\repos\LukVill\code\R\stats101c\STATS101CRegression"")
readline()
readline()
x <- readline()
filepath <- gsub("\\\\","/",x)
filepath <- paste0(filepath,"/train.csv")
filepath
train <- read.csv("train.csv")
train <- read.csv(filepath)
trainFilepath <- paste0(filepath,"/train.csv")
train <- read.csv(trainFilepath)
trainFilepath <- paste0(filepath,"/train.csv")
train <- read.csv(trainFilepath)
trainFilepath
trainFilepath
filepath <- gsub("\\\\","/",x)
trainFilepath <- paste0(filepath,"/train.csv")
train <- read.csv(trainFilepath)
glimpse(train.csv)
glimpse(train)
library(knitr)
library(tidyverse)
glimpse(train)
library(tidymodels)
glimpse(train)
glimpse(train)
testFilepath <- paste0(filepath,"/test.csv")
test <- read.csv(testFilepath)
glimpse(test)
glimpse(train)
glimpse(test)
glimpse(train)
glimpse(test)
glimpse(train)
glimpse(test)
glimpse(train)
glimpse(test)
glimpse(train)
unique(train$name)
library(stringr)
glimpse(train)
column_desc <- paste0(filepath,"/column_descriptions.csv")
columnDescFilepath <- paste0(filepath,"/column_descriptions.csv")
column_desc <- read.csv(columnDescFilepath)
glimpse(column_desc)
column_desc
view(column_desc)
glimpse(train)
